<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hedwig Explains</title>
    <description>A healthy mind is an inquisitive mind</description>
    <link>https://hiteshhedwig.github.io/hedwig_explains/</link>
    <atom:link href="https://hiteshhedwig.github.io/hedwig_explains/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Sun, 07 Mar 2021 13:23:31 +0530</pubDate>
    <lastBuildDate>Sun, 07 Mar 2021 13:23:31 +0530</lastBuildDate>
    <generator>Jekyll v4.2.0</generator>
    
      <item>
        <title>Intuition behind Random Forest</title>
        <description>&lt;h1 id=&quot;what-are-we-gonna-do-in-this-blog&quot;&gt;What are we gonna do in this blog?&lt;/h1&gt;
&lt;p&gt;Learning about what goes behind random forest. What is it that beginner struggles understanding random forest. What makes random forest so powerful. Further, we will discuss intuition behind random forest. Explaining random forest in detail with own handcrafted code and sklearn provided.&lt;/p&gt;

&lt;h1 id=&quot;personal-experience&quot;&gt;Personal Experience&lt;/h1&gt;
&lt;p&gt;When i was starting out with Machine Learning. All i could see the hype of Random Forest being powerful and quite handy in use. I was abit curious. So, i started learning about it in depth. It became a bit hard to comprehend the words like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ensemble&lt;/code&gt; and random forest in general. But after understanding it, i can say it‚Äôs really makes sense why random forest works. I‚Äôll be sharing what are my key insights on this.&lt;/p&gt;

&lt;h1 id=&quot;what-is-the-intuition-behind-random-forest&quot;&gt;What is the intuition behind Random Forest?&lt;/h1&gt;
&lt;p&gt;Random Forest is derived from the concept of Decision Tree. Assuming you know what decision trees are. In a nutshell, When we use lots of decision trees (i.e. 20,100,150) to train &amp;amp; predict the input data. This lot (or Group) of decision trees are known as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ensemble&lt;/code&gt;. Rather than using single decision tree to finalize decision. We use many of them. It‚Äôs same as imagine you have to decide which book to buy for statistics. When you do is talking to many people and then buy which most of the people prefer.&lt;/p&gt;

&lt;p&gt;Another example: Let‚Äôs say you going to interview. So there will be different rounds of interview and you will be evaluated on different features of yours. Finally, getting selected or not would be what most of the interviewer perceive. If 2 out of 3 agree with selection you will be selected. If 2 out of 3 don‚Äôt agree with selection, then you will be rejected.&lt;/p&gt;

&lt;p&gt;Same Goes in Random Forest: You take many decision trees (it could be thousands too), for now let‚Äôs say 100 and each of them trained on random data points(row) of training data. Then you use, testing data and each decision tree will predict according to the feature they have been trained on.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Important: All the decision trees shouldn‚Äôt be trained on same features. That could lead to biased predictions.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Training on random features(reason why random forest are called random) allows to create more flexible and ungreedy algorithm. Decision tree uses &lt;a href=&quot;https://www.edureka.co/community/46109/what-is-greedy-approach-in-decision-tree-algorithm&quot;&gt;greedy algorithm&lt;/a&gt;.
So, it‚Äôs important to feed random features.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/7/76/Random_forest_diagram_complete.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I hope, you get a bit clarity what it means when we say random forest. Although, your concepts will be totally cleared when you dive into coding the decision tree from scratch.&lt;/p&gt;

&lt;h1 id=&quot;coding-our-own-random-forest&quot;&gt;Coding our own Random forest&lt;/h1&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&amp;gt; from sklearn.datasets import make_moons
&amp;gt; from sklearn.model_selection import train_test_split

&amp;gt; mo= make_moons(n_samples=10000, noise=0.4) #creating toy data
&amp;gt; X_train, X_test, y_train, y_test= train_test_split(mo[0], mo[1], test_size=0.2, random_state=42)
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Small peak into data and label.We are looking at first 5 data points and their label(or target). As you can see below, Left side array is X and Y value. And Right Side Array is labels of respective row value.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&amp;gt; X_train[:5], y_train[:5]

(array([[ 0.10186633, -0.20643133],
        [-0.24668162,  1.0486827 ],
        [-0.57215016,  0.30076258],
        [ 0.05560597,  0.9361636 ],
        [-0.91425428, -0.33931685]]), array([1, 0, 0, 1, 0]))
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Just a simple look at our data. Green and Purple are the different classes and in this we have to predict if X and Y coordinates are provided what will be the class of the point.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;%matplotlib inline
import matplotlib.pyplot as plt

plt.scatter(mo[0][:,0], mo[0][:,1], c=mo[1], s=1)
plt.show()
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/hedwig_explains/img/moon.png&quot; alt=&quot;plot&quot; /&gt;&lt;/p&gt;

</description>
        <pubDate>Thu, 11 Feb 2021 00:00:00 +0530</pubDate>
        <link>https://hiteshhedwig.github.io/hedwig_explains/2021/02/11/intuition-behind-random-forest/</link>
        <guid isPermaLink="true">https://hiteshhedwig.github.io/hedwig_explains/2021/02/11/intuition-behind-random-forest/</guid>
        
        <category>randomforest</category>
        
        <category>datascience</category>
        
        <category>intuition</category>
        
        
      </item>
    
      <item>
        <title>Implementation of Xception Model</title>
        <description>&lt;p&gt;&lt;img src=&quot;https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcR6duP6j9BjgUWQ26-l22ONwGXfyOvelAfUKQ&amp;amp;usqp=CAU&quot; alt=&quot;xception&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;what-are-we-doing-in-this-blog&quot;&gt;What are we doing in this blog?&lt;/h1&gt;
&lt;p&gt;If you are here, then you know what are we doing. But still for the sake of clarity:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;We are implementing popular Xception Network as represented by this &lt;a href=&quot;https://arxiv.org/abs/1610.02357&quot;&gt;paper&lt;/a&gt;. In this blog, i‚Äôll be sharing my notes and learnings from this paper &amp;amp; Implemented code as well.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;intro&quot;&gt;Intro:&lt;/h1&gt;
&lt;p&gt;After GoogLeNet proposal of inception module have led in Surge of various improved inception network. In case, you are instantly thinking about the movie ‚Äòinception‚Äô. Yeah, that‚Äôs right. It‚Äôs taken from there. Convolutions within convolutions, this is inception module.&lt;/p&gt;

&lt;p&gt;But what does inception module does differently?&lt;/p&gt;

&lt;p&gt;It significantly reduces computational costs. Idea is not only about making accurate models but also making them deployable in outer world hardwares. Andrew Ng explains it the best in this &lt;a href=&quot;https://www.youtube.com/watch?v=C86ZXvgpejM&quot;&gt;video&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Below, Image represents standard GoogLeNet proposed inception module. 
1x1 for dimensions reductions. And later on we are concatenating the output of the each branch of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;base&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://postimg.cc/TLxZ8fh2&quot;&gt;&lt;img src=&quot;https://i.postimg.cc/cHtZnJS3/xcep1.png&quot; alt=&quot;xcep1.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1512.00567&quot;&gt;Paper&lt;/a&gt; - ‚ÄúRethinking the Inception Architecture for Computer Vision‚Äù talks about getting rid of 5x5 convolutions and substituting it with two 3x3 convolution layers. This can result in dramatic decrease in computational costs from 120 millions to 1.2 million parameters &amp;amp; this is a giant leap of faith.
Author also suggests using asymmetric convolutions, e.g. n √ó 1. For example: using a 3 √ó 1 convolution followed by a 1 √ó 3 convolution
is equivalent to sliding a two layer network with the same receptive field as in a 3 √ó 3 convolution. But in practicality following issue was addressed in paper: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;we have found that employing this factorization does not work well on early layers, but it gives very good results on medium grid-sizes (On m √ó m feature maps, where
m ranges between 12 and 20).&quot;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://postimg.cc/crPky0bq&quot;&gt;&lt;img src=&quot;https://i.postimg.cc/9QQ69fPf/xcep2.png&quot; alt=&quot;xcep2.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;After that author of Xception &lt;a href=&quot;https://arxiv.org/abs/1610.02357&quot;&gt;paper&lt;/a&gt; brought new improvement in the module which gives more better compactness and fairly easy implementation in code.&lt;/p&gt;

&lt;p&gt;But what is this xception?&lt;/p&gt;

&lt;p&gt;Slightly different Xception is! Ofcourse, its an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;extreme Inception module&lt;/code&gt;.&lt;/p&gt;

&lt;h1 id=&quot;xception-complexity-yet-simplicity&quot;&gt;Xception complexity, yet simplicity:&lt;/h1&gt;

&lt;p&gt;Now after you have fair idea of what inception module looks like how it improved.&lt;/p&gt;

&lt;p&gt;An ‚Äúextreme‚Äù version of an Inception module, based on
this stronger hypothesis, would first use a 1x1 convolution to
map cross-channel correlations, and would then separately
map the spatial correlations of every output channel.&lt;/p&gt;

&lt;p&gt;This might be easily explained with the help of image:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://postimg.cc/rKRg97Ff&quot;&gt;&lt;img src=&quot;https://i.postimg.cc/jdZ9RbVY/xcep3.png&quot; alt=&quot;xcep3.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;As you can see, Input (let‚Äôs say 64x150x150) goes through 1x1 convolutions and the output of this uses various 3x3 convolutions. This seperately goes through every output channels. This is almost same as depthwise seperable convolutions. Commonly called
‚Äúseparable convolution‚Äù. This is, a spatial convolution performed independently over each channel of an input, followed by a pointwise convolution, i.e. a 1x1 convolution, projecting the channels output by the depthwise convolution onto a new channel space.&lt;/p&gt;

&lt;p&gt;Incase, this looks hard to under no worries we will understand it in code!
In tensorflow and keras it‚Äôs pretty easy to deal with separable conv. But in pytorch we have to change only one parameter in normal &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nn.Conv2d&lt;/code&gt;. As follows: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nn.Conv2d(in_channel, out_channel,3, groups=in_channel, padding=1)&lt;/code&gt;. ‚Äògroups‚Äô argument must be multiple of in_channel. This followed by  pointwise convolution will complete our aim.&lt;/p&gt;

&lt;p&gt;In pytorch official documentation, (At the time of writing this blog) they don‚Äôt say much about depthwise seperable conv.&lt;/p&gt;

&lt;h2 id=&quot;depthwise-separable-convolutions&quot;&gt;DepthWise Separable Convolutions&lt;/h2&gt;

&lt;p&gt;Depthwise separable convolutions as usually implemented perform first channel-wise spatial convolution and then perform 1x1 convolution, whereas Inception performs the 1x1 convolution first. Below is a sample of how seperable Conv. is implemented ‚Äì&lt;/p&gt;

&lt;p&gt;Channel-wise spatial 3x3 convolution:
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nn.Conv2d(channels[0], channels[0],3, groups=channels[0], padding=1)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Point-wise 1x1 convolution:
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nn.Conv2d(channels[0], channels[1],1)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;These will be used often in the Xception architecture. Before we proceed let‚Äôs look at complete architecture so we know what are we doing..&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://postimg.cc/sBmJXrwg&quot;&gt;&lt;img src=&quot;https://i.postimg.cc/TwMNt2bg/xcep4.png&quot; alt=&quot;xcep4.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Dividing entire network into 3 sections:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Entry Flow&lt;/li&gt;
  &lt;li&gt;Middle Flow (repeated 8 times)&lt;/li&gt;
  &lt;li&gt;Exit Flow&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you look closely, you will see skip connections also (i.e the Conv 1x1 layer which take previous input layer and adding in later layer). This is a bit similar with ResNet? Using residual layers and adding them up! This seen to significantly improve the accuracy of model without overfitting.&lt;/p&gt;

&lt;p&gt;We are first implementing DepthWiseSeperable.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Note: Class DepthWiseSeperable include whole block between the skip connection as you can see in above image.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In class below we are taking channels list input. Which further will be used for parameters of seperable convolutions.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;class DepthWiseSeparable(nn.Module):
    def __init__(self, channels, middle_flow= False):
        super(DepthWiseSeparable, self).__init__()
        
        # block for entry flow
        if middle_flow== False: 
        
            self.block= nn.Sequential(
                nn.ReLU(),
                nn.Conv2d(channels[0], channels[0],3, groups=channels[0], padding=1),
                nn.Conv2d(channels[0], channels[1],1),
                nn.BatchNorm2d( channels[1]),
                nn.ReLU(),
                nn.Conv2d( channels[1], channels[1],3, groups=channels[1], padding=1),
                nn.Conv2d( channels[1], channels[1],1),
                nn.BatchNorm2d(channels[1]),
                nn.MaxPool2d(3,stride=2, padding=1),
            )
        
        # block for middle flow
        if middle_flow==True:
            self.block= nn.Sequential(
                nn.ReLU(),
                nn.Conv2d(channels[0], channels[0],3, groups=channels[0], padding=1),
                nn.Conv2d(channels[0], channels[1],1),
                nn.BatchNorm2d( channels[1]),
                nn.ReLU(),
                nn.Conv2d( channels[1], channels[1],3, groups=channels[1], padding=1),
                nn.Conv2d( channels[1], channels[1],1),
                nn.BatchNorm2d(channels[1]),
                nn.ReLU(),
                nn.Conv2d( channels[1], channels[1],3, groups=channels[1], padding=1),
                nn.Conv2d( channels[1], channels[1],1),                
            )

        # block for exit flow
        
        if middle_flow=='Exit':
            self.block= nn.Sequential(
                nn.Conv2d(channels[0], channels[0],3, groups=channels[0], padding=1),
                nn.Conv2d(channels[0], channels[1],1),
                nn.BatchNorm2d( channels[1]),
                nn.ReLU(),
                nn.Conv2d( channels[1], channels[1],3, groups=channels[1], padding=1),
                nn.Conv2d( channels[1], channels[2],1),
                nn.BatchNorm2d(channels[2]),
                nn.ReLU(),
            )


    
    def forward(self,x):
        x= self.block(x)
        return x

&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Below is Main xception class which will use above class to create whole network.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;class Xception(nn.Module):
    def __init__(self, DepthWiseSeparable):
        super(Xception, self).__init__()

        self.conv1_3x3 = nn.Conv2d(3,32,3,stride=2,padding=1)
        self.bn1 =nn.BatchNorm2d(32)
        self.relu = nn.ReLU()

        self.conv2_3x3= nn.Conv2d(32,64,3,stride=1,padding=1)
        self.bn2 =nn.BatchNorm2d(64)
        self.relu= nn.ReLU()
        #Entry flow
        self.block_3x3= DepthWiseSeparable(channels=[64,128])
        self.downsample_1= nn.Conv2d(64,128,1,stride=2)

        self.block_3x3_256= DepthWiseSeparable(channels=[128,256])
        self.downsample_2= nn.Conv2d(128,256,1,stride=2)

        self.block_3x3_728= DepthWiseSeparable(channels=[256,728])
        self.downsample_3= nn.Conv2d(256,728,1,stride=2)
        #Middle Flow
        self.block_3x3_middle= DepthWiseSeparable(channels=[728,728], middle_flow=True)
        #Exit flow
        self.block_3x3_exit = DepthWiseSeparable(channels=[728,1024])
        self.downsample_4= nn.Conv2d(728,1024,1,stride=2)

        self.block_3x3_exit_2 = DepthWiseSeparable(channels=[1024,1536,2048], middle_flow='Exit')
        
        self.avgpool= nn.AdaptiveAvgPool2d((1,1))

        self.fc= nn.Linear(2048,1000)

    def forward(self,x):
        x= self.relu(self.bn1(self.conv1_3x3(x)))
        print(x.size())
        x_identity = self.relu(self.bn2(self.conv2_3x3(x)))
        print(x_identity.size())
        x_res_1= self.block_3x3(x_identity)
        print(x_res_1.size())
        x_identity= self.downsample_1(x_identity)
        print(x_identity.size())
        
        x_identity= x_identity+x_res_1

        x_res_2= self.block_3x3_256(x_identity)
        print(x_res_2.size())
        x_identity= self.downsample_2(x_identity)
        print(x_identity.size())

        x_identity= x_identity+x_res_2
    
        x_res_3= self.block_3x3_728(x_identity)
        print(x_res_3.size())
        x_identity= self.downsample_3(x_identity)
        print(x_identity.size())
        x_identity= x_identity+x_res_3

        for i in range(9):
            x_res_4= self.block_3x3_middle(x_identity)
            x_identity= x_identity+x_res_4

        print(x_identity.size())
        
        x_res_5= self.block_3x3_exit(x_identity)
        x_identity= self.downsample_4(x_identity)

        x_identity= x_identity+x_res_5
        print(x_identity.size())

        x_res_6= self.block_3x3_exit_2(x_identity)
        print(x_res_6.size())

        x= self.avgpool(x_res_6)
        print(x.size())

        x= x.view(x.shape[0],-1)
        print(x.size())

        x= self.fc(x)
        print(x.size())       
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;img= torch.randn(1,3,299,299)

net= Xception(DepthWiseSeparable)
net(img)

&amp;gt; Output:
torch.Size([1, 32, 150, 150])
torch.Size([1, 64, 150, 150])
torch.Size([1, 128, 75, 75])
torch.Size([1, 128, 75, 75])
torch.Size([1, 256, 38, 38])
torch.Size([1, 256, 38, 38])
torch.Size([1, 728, 19, 19])
torch.Size([1, 728, 19, 19])
torch.Size([1, 728, 19, 19])
torch.Size([1, 1024, 10, 10])
torch.Size([1, 2048, 10, 10])
torch.Size([1, 2048, 1, 1])
torch.Size([1, 2048])
torch.Size([1, 1000])
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;model-&quot;&gt;Model :&lt;/h2&gt;
&lt;p&gt;Our model will look like something like&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;Xception(
  (conv1_3x3): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU()
  (conv2_3x3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (block_3x3): DepthWiseSeparable(
    (block): Sequential(
      (0): ReLU()
      (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)
      (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))
      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): ReLU()
      (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
      (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
      (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    )
  )
  (downsample_1): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))
  (block_3x3_256): DepthWiseSeparable(
    (block): Sequential(
      (0): ReLU()
      (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)
      (2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
      (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): ReLU()
      (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
      (6): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    )
  )
  (downsample_2): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))
  (block_3x3_728): DepthWiseSeparable(
    (block): Sequential(
      (0): ReLU()
      (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
      (2): Conv2d(256, 728, kernel_size=(1, 1), stride=(1, 1))
      (3): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): ReLU()
      (5): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728)
      (6): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1))
      (7): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    )
  )
  (downsample_3): Conv2d(256, 728, kernel_size=(1, 1), stride=(2, 2))
  (block_3x3_middle): DepthWiseSeparable(
    (block): Sequential(
      (0): ReLU()
      (1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728)
      (2): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1))
      (3): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): ReLU()
      (5): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728)
      (6): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1))
      (7): BatchNorm2d(728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): ReLU()
      (9): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728)
      (10): Conv2d(728, 728, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (block_3x3_exit): DepthWiseSeparable(
    (block): Sequential(
      (0): ReLU()
      (1): Conv2d(728, 728, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=728)
      (2): Conv2d(728, 1024, kernel_size=(1, 1), stride=(1, 1))
      (3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (4): ReLU()
      (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
      (6): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
      (7): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    )
  )
  (downsample_4): Conv2d(728, 1024, kernel_size=(1, 1), stride=(2, 2))
  (block_3x3_exit_2): DepthWiseSeparable(
    (block): Sequential(
      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
      (1): Conv2d(1024, 1536, kernel_size=(1, 1), stride=(1, 1))
      (2): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (3): ReLU()
      (4): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536)
      (5): Conv2d(1536, 2048, kernel_size=(1, 1), stride=(1, 1))
      (6): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (7): ReLU()
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=2048, out_features=1000, bias=True)
)
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description>
        <pubDate>Wed, 28 Oct 2020 00:00:00 +0530</pubDate>
        <link>https://hiteshhedwig.github.io/hedwig_explains/2020/10/28/intutition-behind-xception-model/</link>
        <guid isPermaLink="true">https://hiteshhedwig.github.io/hedwig_explains/2020/10/28/intutition-behind-xception-model/</guid>
        
        <category>code</category>
        
        <category>researchpaper</category>
        
        <category>intuition</category>
        
        
      </item>
    
      <item>
        <title>Changing Folder Name for model training</title>
        <description>&lt;h1 id=&quot;what-are-we-doing-in-this-blog&quot;&gt;What are we doing in this blog?&lt;/h1&gt;

&lt;p&gt;We are changing folders name like this:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Folder Name from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n02113023-Pembroke&lt;/code&gt; Changed to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Pembroke&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Folder Name from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n02113624-toy_poodle&lt;/code&gt; Changed to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Toy Poodle&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Folder Name from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n02115641-dingo&lt;/code&gt; Changed to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Dingo&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If want to learn this, Go on with reading:&lt;/p&gt;

&lt;p&gt;In this, dataset directory. I have downloaded, famous standford &lt;a href=&quot;http://vision.stanford.edu/aditya86/ImageNetDogs/&quot;&gt;dataset&lt;/a&gt;. The Stanford Dogs dataset contains images of 120 breeds of dogs from around the world. This dataset has been built using images and annotation from ImageNet for the task of fine-grained image categorization.&lt;/p&gt;

&lt;p&gt;The name of the folders (which will be used as classes while training) have names like, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n02093256-Staffordshire_bullterrier&lt;/code&gt;. We definitely don‚Äôt want our class to be like that but rather simple &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Staffordshire Bullterrier&lt;/code&gt;. The python script will get rid of any weird characters that are unneccessary.&lt;/p&gt;

&lt;p&gt;Now, we have our path defined where the data is situated. In my case, i had uploaded it to google drive. Time consuming upload, avoid it if possible.&lt;/p&gt;

&lt;p&gt;Let‚Äôs say we have folder name like this:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n02093256-Staffordshire_bullterrier&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Here is our process of obtaining what we want,&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;We first split on the basis of  - (hyphen) charachter&lt;/li&gt;
  &lt;li&gt;Then we obtain list like this: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;['n02093256' , 'Staffordshire_bullterrier']&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;After that, we use slicing technique to select second index.&lt;/li&gt;
  &lt;li&gt;Then after we have what we wanted, we can simply again split on the basis of  _ (underscore)&lt;/li&gt;
  &lt;li&gt;Then we obtain something like this:
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;['Staffordshire','bullterrier']&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;After we have what we wanted we can simply join the list back. And use capitalize to make first letter of word capitalize.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;üìù Note: This code will need to be modified according to the folder name you are dealing with.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;'''
THIS PYTHON CODE CHANGES NAME OF FILES IN A FOLDER
'''

import os
import string


def change_name(folder_name): 
    folder_name=folder_name.split('-') #n02113023-Pembroke-&amp;gt;['n02113023','Pembroke'] 
    folder_name= ' '.join(folder_name[1:]) #Selecting index after 1 and joining them
    folder_name=folder_name.split('_') # Again splitting becayse name seem to be like Staffordshire_bullterrier
    folder_name= ' '.join(folder_name) #again joining after getting rid of _ 
    return string.capwords(folder_name) #or we can use capitalize()

#iterating over all the folders and changing file name
for fn in os.listdir(path):

    new_path= os.path.join(path,fn)
    #folder_name= os.path.basename(new_path) #alternative use of to know file name    
    new_folder_name= change_name(fn)
    os.rename(os.path.join(path,fn),os.path.join(path,new_folder_name))
    print (f'Folder Name from {fn} Changed to {new_folder_name}')
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;Output :
Folder Name from n02113023-Pembroke Changed to Pembroke
Folder Name from n02093256-Staffordshire_bullterrier Changed to Staffordshire Bullterrier
Folder Name from n02093428-American_Staffordshire_terrier Changed to American Staffordshire Terrier
Folder Name from n02113624-toy_poodle Changed to Toy Poodle
Folder Name from n02100236-German_short-haired_pointer Changed to German Short Haired Pointer
Folder Name from n02115641-dingo Changed to Dingo
Folder Name from n02089867-Walker_hound Changed to Walker Hound
Folder Name from n02099601-golden_retriever Changed to Golden Retriever
Folder Name from n02105162-malinois Changed to Malinois
Folder Name from n02100735-English_setter Changed to English Setter
Folder Name from n02097298-Scotch_terrier Changed to Scotch Terrier
Folder Name from n02095889-Sealyham_terrier Changed to Sealyham Terrier
Folder Name from n02106550-Rottweiler Changed to Rottweiler
Folder Name from n02088094-Afghan_hound Changed to Afghan Hound
Folder Name from n02112018-Pomeranian Changed to Pomeranian
Folder Name from n02099429-curly-coated_retriever Changed to Curly Coated Retriever
Folder Name from n02095314-wire-haired_fox_terrier Changed to Wire Haired Fox Terrier
Folder Name from n02116738-African_hunting_dog Changed to African Hunting Dog
Folder Name from n02091467-Norwegian_elkhound Changed to Norwegian Elkhound
Folder Name from n02096294-Australian_terrier Changed to Australian Terrier
Folder Name from n02108422-bull_mastiff Changed to Bull Mastiff
Folder Name from n02096177-cairn Changed to Cairn
Folder Name from n02104365-schipperke Changed to Schipperke
Folder Name from n02101556-clumber Changed to Clumber
Folder Name from n02090721-Irish_wolfhound Changed to Irish Wolfhound
Folder Name from n02110806-basenji Changed to Basenji
Folder Name from n02105251-briard Changed to Briard
Folder Name from n02102040-English_springer Changed to English Springer
Folder Name from n02085620-Chihuahua Changed to Chihuahua
Folder Name from n02110063-malamute Changed to Malamute
Folder Name from n02109525-Saint_Bernard Changed to Saint Bernard
Folder Name from n02107683-Bernese_mountain_dog Changed to Bernese Mountain Dog
Folder Name from n02111129-Leonberg Changed to Leonberg
Folder Name from n02094114-Norfolk_terrier Changed to Norfolk Terrier
Folder Name from n02110627-affenpinscher Changed to Affenpinscher
Folder Name from n02111277-Newfoundland Changed to Newfoundland
Folder Name from n02112350-keeshond Changed to Keeshond
Folder Name from n02106382-Bouvier_des_Flandres Changed to Bouvier Des Flandres
Folder Name from n02093647-Bedlington_terrier Changed to Bedlington Terrier
Folder Name from n02107312-miniature_pinscher Changed to Miniature Pinscher
Folder Name from n02115913-dhole Changed to Dhole
Folder Name from n02111889-Samoyed Changed to Samoyed
Folder Name from n02091032-Italian_greyhound Changed to Italian Greyhound
Folder Name from n02085782-Japanese_spaniel Changed to Japanese Spaniel
Folder Name from n02098286-West_Highland_white_terrier Changed to West Highland White Terrier
Folder Name from n02090379-redbone Changed to Redbone
Folder Name from n02099849-Chesapeake_Bay_retriever Changed to Chesapeake Bay Retriever
Folder Name from n02106662-German_shepherd Changed to German Shepherd
Folder Name from n02105505-komondor Changed to Komondor
Folder Name from n02087046-toy_terrier Changed to Toy Terrier
Folder Name from n02098105-soft-coated_wheaten_terrier Changed to Soft Coated Wheaten Terrier
Folder Name from n02099267-flat-coated_retriever Changed to Flat Coated Retriever
Folder Name from n02104029-kuvasz Changed to Kuvasz
Folder Name from n02096585-Boston_bull Changed to Boston Bull
Folder Name from n02097130-giant_schnauzer Changed to Giant Schnauzer
Folder Name from n02086646-Blenheim_spaniel Changed to Blenheim Spaniel
Folder Name from n02112706-Brabancon_griffon Changed to Brabancon Griffon
Folder Name from n02111500-Great_Pyrenees Changed to Great Pyrenees
Folder Name from n02088466-bloodhound Changed to Bloodhound
Folder Name from n02101006-Gordon_setter Changed to Gordon Setter
Folder Name from n02108089-boxer Changed to Boxer
Folder Name from n02113799-standard_poodle Changed to Standard Poodle
Folder Name from n02086910-papillon Changed to Papillon
Folder Name from n02113712-miniature_poodle Changed to Miniature Poodle
Folder Name from n02095570-Lakeland_terrier Changed to Lakeland Terrier
Folder Name from n02098413-Lhasa Changed to Lhasa
Folder Name from n02106030-collie Changed to Collie
Folder Name from n02092002-Scottish_deerhound Changed to Scottish Deerhound
Folder Name from n02110185-Siberian_husky Changed to Siberian Husky
Folder Name from n02088238-basset Changed to Basset
Folder Name from n02097047-miniature_schnauzer Changed to Miniature Schnauzer
Folder Name from n02108551-Tibetan_mastiff Changed to Tibetan Mastiff
Folder Name from n02105412-kelpie Changed to Kelpie
Folder Name from n02106166-Border_collie Changed to Border Collie
Folder Name from n02102480-Sussex_spaniel Changed to Sussex Spaniel
Folder Name from n02110958-pug Changed to Pug
Folder Name from n02109961-Eskimo_dog Changed to Eskimo Dog
Folder Name from n02096437-Dandie_Dinmont Changed to Dandie Dinmont
Folder Name from n02091831-Saluki Changed to Saluki
Folder Name from n02105056-groenendael Changed to Groenendael
Folder Name from n02113186-Cardigan Changed to Cardigan
Folder Name from n02102973-Irish_water_spaniel Changed to Irish Water Spaniel
Folder Name from n02113978-Mexican_hairless Changed to Mexican Hairless
Folder Name from n02092339-Weimaraner Changed to Weimaraner
Folder Name from n02105855-Shetland_sheepdog Changed to Shetland Sheepdog
Folder Name from n02089973-English_foxhound Changed to English Foxhound
Folder Name from n02102318-cocker_spaniel Changed to Cocker Spaniel
Folder Name from n02097658-silky_terrier Changed to Silky Terrier
Folder Name from n02088632-bluetick Changed to Bluetick
Folder Name from n02091635-otterhound Changed to Otterhound
Folder Name from n02108000-EntleBucher Changed to Entlebucher
Folder Name from n02094258-Norwich_terrier Changed to Norwich Terrier
Folder Name from n02112137-chow Changed to Chow
Folder Name from n02094433-Yorkshire_terrier Changed to Yorkshire Terrier
Folder Name from n02097474-Tibetan_terrier Changed to Tibetan Terrier
Folder Name from n02100583-vizsla Changed to Vizsla
Folder Name from n02097209-standard_schnauzer Changed to Standard Schnauzer
Folder Name from n02096051-Airedale Changed to Airedale
Folder Name from n02091134-whippet Changed to Whippet
Folder Name from n02107908-Appenzeller Changed to Appenzeller
Folder Name from n02105641-Old_English_sheepdog Changed to Old English Sheepdog
Folder Name from n02085936-Maltese_dog Changed to Maltese Dog
Folder Name from n02087394-Rhodesian_ridgeback Changed to Rhodesian Ridgeback
Folder Name from n02108915-French_bulldog Changed to French Bulldog
Folder Name from n02100877-Irish_setter Changed to Irish Setter
Folder Name from n02109047-Great_Dane Changed to Great Dane
Folder Name from n02107574-Greater_Swiss_Mountain_dog Changed to Greater Swiss Mountain Dog
Folder Name from n02086240-Shih-Tzu Changed to Shih Tzu
Folder Name from n02093859-Kerry_blue_terrier Changed to Kerry Blue Terrier
Folder Name from n02086079-Pekinese Changed to Pekinese
Folder Name from n02107142-Doberman Changed to Doberman
Folder Name from n02088364-beagle Changed to Beagle
Folder Name from n02101388-Brittany_spaniel Changed to Brittany Spaniel
Folder Name from n02093754-Border_terrier Changed to Border Terrier
Folder Name from n02089078-black-and-tan_coonhound Changed to Black And Tan Coonhound
Folder Name from n02099712-Labrador_retriever Changed to Labrador Retriever
Folder Name from n02093991-Irish_terrier Changed to Irish Terrier
Folder Name from n02090622-borzoi Changed to Borzoi
Folder Name from n02091244-Ibizan_hound Changed to Ibizan Hound
Folder Name from n02102177-Welsh_springer_spaniel Changed to Welsh Springer Spaniel
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Hopefully, this post was helpful in some way !&lt;/p&gt;

</description>
        <pubDate>Tue, 20 Oct 2020 00:00:00 +0530</pubDate>
        <link>https://hiteshhedwig.github.io/hedwig_explains/2020/10/20/changing-folder-name-for-model-training/</link>
        <guid isPermaLink="true">https://hiteshhedwig.github.io/hedwig_explains/2020/10/20/changing-folder-name-for-model-training/</guid>
        
        <category>python</category>
        
        <category>filename</category>
        
        <category>datascience</category>
        
        <category>dog-breed</category>
        
        
      </item>
    
      <item>
        <title>[Spirituality] Contemplating on Great Verses By Yogi Vasistha</title>
        <description>&lt;p&gt;&lt;img src=&quot;http://2.bp.blogspot.com/-rj5tXab7_aA/UdGNLPctzNI/AAAAAAAAAE0/zH3rlohK5rI/s960/Yoga+Vasistha+-+muneshkumarkell-blogspot.jpg&quot; alt=&quot;yogi&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;verse-&quot;&gt;Verse ‚Äì&lt;/h2&gt;
&lt;p&gt;(I) : When the truth is known, all descriptions cease, and silence alone remains.&lt;/p&gt;

&lt;p&gt;(II) : The mind is purified by persistent contemplation of truth. Only when the mind is totally purified of all conditioning does it regain its utter purity; that pure mind experiences liberation&lt;/p&gt;

&lt;p&gt;(III) : Bondage is none other than the notion of an object. The notions of I and the world are but shadows, not truth. Such notions alone create objects; these objects are neither true nor false. Therefore abandon the notions of I and this and remain established in the truth&lt;/p&gt;

&lt;p&gt;(IV) : It is only when the mind has become devoid of all attachment, when it is not swayed by the pairs of opposites, when it is not attracted by objects and when it is totally independent of all supports, that it is freed from the cage of delusion.&lt;/p&gt;

&lt;p&gt;(V) : Wealth is the mother of evil. Sense-pleasure is the source of pain. Misfortune is the best fortune. Rejection by all is victory. Life, honor and noble qualities blossom and attain fruition in one whose conduct and behavior are good and pleasant, who is devoted to seclusion and who does not crave for the pleasures of the world, which lead to suffering.&lt;/p&gt;

&lt;p&gt;(VI) : When in a pure mind there arise concepts and notions, the world appearance comes into being. But, when the mind gives up the subject-object relationship it has with the world, it is instantly absorbed in the infinite.&lt;/p&gt;

&lt;p&gt;(VII) : When you are free from all concerns about the objects of the world, you will be established in non-dual consciousness, and that is final liberation. Live without being swayed by likes and dislikes, attraction and aversion, without any desires or cravings. Constantly seek to discover the supreme peace.&lt;/p&gt;

&lt;p&gt;(VIII) : One should enjoy the delight that flows from peace. The man whose mind is well-controlled is firmly established in peace. When the heart is thus established in peace, there arises the pure bliss of the Self without delay.&lt;/p&gt;

&lt;p&gt;(IX) : Consciousness free from the limitations of the mind is known as the inner intelligence: it is the essential nature of no-mind. That is the reality, that is supreme consciousness, that is the state known as the supreme self, that is omniscience&lt;/p&gt;

&lt;p&gt;(X) : O mind, abandon this perception of diversity and realize the unreality of your own independence from the infinite consciousness: this is liberation.&lt;/p&gt;

&lt;p&gt;(XI) : Death does not wish to kill one who does not have raga-dvesa (attraction and aversion) nor false notions and mental habits. Death does not wish to kill one who does not suffer from mental illness, who does not entertain desires and hopes which give rise to anxieties and worry, who is not poisoned by greed, whose body and mind are not burnt by the fire of anger and hate, who is not churned and ground by the mill of lust, who is firmly established in the pure awareness of Brahman and the absolute and whose mind is not distracted like a monkey.&lt;/p&gt;

&lt;p&gt;(XII) : In fact, that bliss is inexpressible and indescribable and should not even be called happiness! The mind of the knower of the truth is no-mind: it is pure satva. After living with such no-mind for some time, there arises the state known as turiya-atita (the state beyond the transcendental, or the turiya state).&lt;/p&gt;

&lt;p&gt;(XIII) : The inner light that shines as pure experiencing in all beings, that alone is the self which is indicated by the word I: this is for certain.&lt;/p&gt;

&lt;p&gt;[Vasistha:] ‚Äú&lt;em&gt;It is wrong perception that sees a bracelet in gold. The mere appearance becomes the cause for such wrong perception. This Maya (unreal appearance) is but a figure of speech, the appearance has the same relation to the supreme self that a wave has to the ocean. When one sees this truth, the appearance ceases to be a delusion. It is on account of ignorance that this long-dream world-appearance appears to be real: thus does the Individual Self come into being. But when the truth is realized, it is seen that all this is the self&lt;/em&gt;.‚Äù&lt;/p&gt;

&lt;p&gt;(XIV) : Rama, expand the mind with the mind. Remain at peace within your self, seeing the one infinite being in all. Like the king Bhagiratha you will achieve the impossible if you are able to remain firm in your knowledge of the truth and if you engage yourself in appropriate action in a life characterized by effortless experiencing of the natural course of events.&lt;/p&gt;

&lt;p&gt;[Vasistha:]
‚Äú&lt;em&gt;He (King Bhagiratha) approached his guru Tritala and prayed, Lord, how can one put an end to this sorrow and to old age, death and delusion which contribute to repeated birth here?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Tritala said: Sorrow ceases, all the bondages are cut and doubts are dispelled when one is fully established in the equanimity of the self for a long time, when the perception of division has ceased and when there is the experience of fullness through the knowledge of that which is to be known. What is to be known?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;It is the self which is pure and which is of the nature of pure consciousness which is omnipresent and eternal.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Bhagiratha asked: I know that the self alone is real and the body, etc., are not real. But how is it that it is not perfectly clear to me?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Tritala said: Such intellectual knowledge is not knowledge! Unattachment to wife, son and house, equanimity in pleasure and pain, love of solitude, being firmly established in self-knowledge ‚Äî this is knowledge, all else is ignorance! Only when the egosense is thinned out does this self-knowledge arise.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Bhagiratha asked: Since this egosense is firmly established in this body, how can it be uprooted?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Tritala replied: By self-effort and by resolutely turning away from the pursuit of pleasure. And by the resolute breaking down of the prison-house of shame (false dignity), etc. If you abandon all this and remain firm, the egosense will vanish and you will realize that you are the supreme being&lt;/em&gt;.‚Äù&lt;/p&gt;
</description>
        <pubDate>Wed, 14 Oct 2020 00:00:00 +0530</pubDate>
        <link>https://hiteshhedwig.github.io/hedwig_explains/2020/10/14/contemplating-on-great-verses-by-yogi-vasistha/</link>
        <guid isPermaLink="true">https://hiteshhedwig.github.io/hedwig_explains/2020/10/14/contemplating-on-great-verses-by-yogi-vasistha/</guid>
        
        <category>spirituality</category>
        
        <category>contemplating_series</category>
        
        
      </item>
    
      <item>
        <title>Biggest Dataset on Internet</title>
        <description>&lt;h1 id=&quot;what-are-we-doing-and-why&quot;&gt;What are we doing? And Why?&lt;/h1&gt;
&lt;p&gt;If you are a datascientist or computer vision researcher who always looking for neat image  or any sort of dataset because it‚Äôs sometimes so hard to find right dataset for you. In this post, i am sharing some resources which would be super helpful for you. I will also show the right way to download them in case of &lt;strong&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Google Open Image Dataset&lt;/code&gt;&lt;/strong&gt;. What right way you may ask? It‚Äôs simply a python script which will do the job for you. You don‚Äôt need to rush in anyway.&lt;/p&gt;

&lt;h1 id=&quot;open-images-dataset-v6&quot;&gt;Open Images Dataset V6&lt;/h1&gt;

&lt;p&gt;When i was starting out from scratch. It was quite difficult to know from where to download the dataset. Or if that dataset right for you. Open Images Dataset V6 by Google is an amazing source to download the data.&lt;/p&gt;

&lt;p&gt;You can find it &lt;a href=&quot;https://storage.googleapis.com/openimages/web/visualizer/index.html?set=train&amp;amp;type=detection&amp;amp;c=%2Fm%2F0pg52&quot;&gt;here&lt;/a&gt;. There will be plethora of categories in the dropdown menu. It would look something like this.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://postimg.cc/ygqVGYWV&quot;&gt;&lt;img src=&quot;https://i.postimg.cc/1tXff8QN/googleos.png&quot; alt=&quot;googleos.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;brief&quot;&gt;Brief&lt;/h2&gt;

&lt;p&gt;As you can see, the category for this tutorial i have chosen is taxi. You may chose anything else, Ofcourse!. There are several filters on the top of red bar in the website which is important to know about. Like:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Subset : (Train, Validation)&lt;/li&gt;
  &lt;li&gt;Type: (Detection, Segementation)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Subset is only to show you the content which will be downloaded if you download train or validation filtered data.&lt;/p&gt;

&lt;p&gt;Type is crucial, it will give you whatever type of problem deal with. For example, for this example we have used detection. So the images we are getting is bounding boxes. If you switch it to, segmentation you get segemented image. As simple as that.&lt;/p&gt;

&lt;h2 id=&quot;how-to-download&quot;&gt;How to download?&lt;/h2&gt;

&lt;p&gt;It‚Äôs quite difficult to ambigous to download from the website. But fortunately we have tool which makes it easy to one liner!&lt;/p&gt;

&lt;p&gt;We use a tool name &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;OIDv4_ToolKit&lt;/code&gt; available on &lt;a href=&quot;https://github.com/theAIGuysCode/OIDv4_ToolKit&quot;&gt;github&lt;/a&gt;. It makes is fairly easy to download images.&lt;/p&gt;

&lt;p&gt;Cloning the github repo.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;üìù Note: If you are running the command in a terminal. Omit ‚Äú!‚Äù .&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&amp;gt; git clone https://github.com/theAIGuysCode/OIDv4_ToolKit.git 
Cloning into 'OIDv4_ToolKit'...
remote: Enumerating objects: 444, done.
remote: Total 444 (delta 0), reused 0 (delta 0), pack-reused 444
Receiving objects: 100% (444/444), 34.09 MiB | 35.95 MiB/s, done.
Resolving deltas: 100% (157/157), done.
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Moving inside directory and extracting some files. You don‚Äôt need to bother much about this, just copy paste and run on your machine.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&amp;gt; cd OIDv4_ToolKit/
&amp;gt; curl &quot;https://d1vvhvl2y92vvt.cloudfront.net/awscli-exe-linux-x86_64.zip&quot; -o &quot;awscliv2.zip&quot;
&amp;gt; unzip awscliv2.zip
&amp;gt; sudo ./aws/install
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Now, here comes the magic. One command where you specify :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;class&lt;/code&gt; : In our case, we will download &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Taxi&lt;/code&gt; images. You can download multiple classes by just typing class one after another.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;type_csv&lt;/code&gt;: Do you want to download train data? Validation data?&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;limit&lt;/code&gt;: How many images we want to download? I am downloading 100 as an example.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&amp;gt; python main.py downloader --classes Taxi --type_csv train --limit 100
.'   `.|_   _||_   _ `.         | |  | |   
		/  .-.  \ | |    | | `. \ _   __ | |__| |_  
		| |   | | | |    | |  | |[ \ [  ]|____   _| 
		\  `-'  /_| |_  _| |_.' / \ \/ /     _| |_  
		 `.___.'|_____||______.'   \__/     |_____|
	

             _____                    _                 _             
            (____ \                  | |               | |            
             _   \ \ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ 
            | |   | / _ \| | | |  _ \| |/ _ \ / _  |/ || |/ _  )/ ___)
            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    
            |_____/ \___/ \____|_| |_|_|\___/ \_||_|\____|\____)_|    
                                                          
        
    [INFO] | Downloading Taxi.
   [ERROR] | Missing the class-descriptions-boxable.csv file.
[DOWNLOAD] | Do you want to download the missing file? [Y/n] Y
...145%, 0 MB, 31097 KB/s, 0 seconds passed
[DOWNLOAD] | File class-descriptions-boxable.csv downloaded into OID/csv_folder/class-descriptions-boxable.csv.
   [ERROR] | Missing the train-annotations-bbox.csv file.
[DOWNLOAD] | Do you want to download the missing file? [Y/n] Y
...100%, 1138 MB, 33727 KB/s, 34 seconds passed
[DOWNLOAD] | File train-annotations-bbox.csv downloaded into OID/csv_folder/train-annotations-bbox.csv.

Taxi
    [INFO] | Downloading train images.
    [INFO] | [INFO] Found 1434 online images for train.
    [INFO] | Limiting to 100 images.
    [INFO] | Download of 100 images in train.
100% 100/100 [02:08&amp;lt;00:00,  1.28s/it]
    [INFO] | Done!
    [INFO] | Creating labels for Taxi of train.
    [INFO] | Labels creation completed.
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h1 id=&quot;sample-image-from-data&quot;&gt;Sample image from data&lt;/h1&gt;

&lt;p&gt;Now it has been downloaded. Dataset will be downloaded in the file &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/OID/Dataset/train/&lt;/code&gt;
Let‚Äôs see the sample image?&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;&amp;gt; from PIL import Image
&amp;gt; Image.open('/content/OIDv4_ToolKit/OID/Dataset/train/Taxi/23274c285653cc1c.jpg')
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&quot;https://postimg.cc/Cn5nhxCW&quot;&gt;&lt;img src=&quot;https://i.postimg.cc/3NCXZykJ/car.png&quot; alt=&quot;car.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;So it looks pretty good! Remember i have only downloaded 100 images. You can download with any limit. If its available on dataset. It will be downloaded. We also have bounding boxes in labels folder.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;‚ö° Tip: csv file have been downloaded in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;csv_folder&lt;/code&gt;. You can use it as pandas dataframe for more flexible usage of data.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;open-public-datasets&quot;&gt;Open Public datasets&lt;/h1&gt;
&lt;p&gt;As a data scientist, you dont always deal with image dataset. So, this &lt;a href=&quot;https://github.com/hiteshhedwig/awesome-public-datasets&quot;&gt;Github&lt;/a&gt; Repo got very detailed list of every dataset for gamut of professions.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://postimg.cc/YvzrPwYg&quot;&gt;&lt;img src=&quot;https://i.postimg.cc/0yLzbkNt/dataset.png&quot; alt=&quot;dataset.png&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;‚ö° Tip: If you are new to github. You can fork it and contribute to it as well.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;amazon-google-microsoft-public-dataset&quot;&gt;Amazon, Google, Microsoft Public Dataset&lt;/h1&gt;

&lt;p&gt;Waait.. we just discussed google dataset a while ago. That was especially for image based problems. Incase you want to research for the data yourself that you struggling to find. The &lt;a href=&quot;https://datasetsearch.research.google.com/&quot;&gt;Google Dataset Search engine&lt;/a&gt; will help you to research more about it.&lt;/p&gt;

&lt;p&gt;Like Google, &lt;a href=&quot;https://registry.opendata.aws/&quot;&gt;Amazon&lt;/a&gt; also have some public dataset to help you with your research.&lt;/p&gt;

&lt;p&gt;And so do, &lt;a href=&quot;https://azure.microsoft.com/en-in/services/open-datasets/catalog/&quot;&gt;Microsoft&lt;/a&gt; .&lt;/p&gt;

&lt;p&gt;Datasets we have discussed so far. They will definitely provide the edge you looking for (if you look correctly). They are almost all you need. Although there are sites like kaggle, datatruks but as we have mentioned google dataset engine. It automatically directs you to the sites.&lt;/p&gt;

</description>
        <pubDate>Mon, 12 Oct 2020 00:00:00 +0530</pubDate>
        <link>https://hiteshhedwig.github.io/hedwig_explains/2020/10/12/biggest-dataset-on-internet/</link>
        <guid isPermaLink="true">https://hiteshhedwig.github.io/hedwig_explains/2020/10/12/biggest-dataset-on-internet/</guid>
        
        <category>dataset</category>
        
        <category>opensource</category>
        
        
      </item>
    
  </channel>
</rss>
